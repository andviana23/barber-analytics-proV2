# ğŸ—„ï¸ Backup & Disaster Recovery â€” Barber Analytics Pro

**EstratÃ©gia de Backup e RecuperaÃ§Ã£o de Desastres**
**VersÃ£o:** 1.0.0
**Data:** 15/11/2025
**Status:** ğŸŸ¡ Em ImplementaÃ§Ã£o

---

## ğŸ“‹ Ãndice

1. [VisÃ£o Geral](#visÃ£o-geral)
2. [PolÃ­tica de Backup](#polÃ­tica-de-backup)
3. [Backup AutomÃ¡tico (Neon)](#backup-automÃ¡tico-neon)
4. [Backup Complementar (pg_dump)](#backup-complementar-pg_dump)
5. [Testes de Restore](#testes-de-restore)
6. [Disaster Recovery Playbook](#disaster-recovery-playbook)
7. [Objetivos RTO/RPO](#objetivos-rtorpo)
8. [Checklist de ValidaÃ§Ã£o](#checklist-de-validaÃ§Ã£o)

---

## ğŸ¯ VisÃ£o Geral

### Escopo

Este documento descreve a estratÃ©gia de **Backup e Disaster Recovery (DR)** para o sistema **Barber Analytics Pro**, incluindo:
- Backups automÃ¡ticos do banco de dados (Neon PostgreSQL)
- Backups complementares via `pg_dump`
- Procedimentos de restore
- Plano de recuperaÃ§Ã£o de desastres
- Testes periÃ³dicos

### Ativos CrÃ­ticos

| Ativo | Criticidade | Backup NecessÃ¡rio |
|-------|-------------|-------------------|
| **Database (Neon)** | ğŸ”´ CrÃ­tico | âœ… SIM |
| **Backend Go (cÃ³digo)** | ğŸŸ¡ Alto | âœ… SIM (Git) |
| **Frontend Next.js (cÃ³digo)** | ğŸŸ¡ Alto | âœ… SIM (Git) |
| **Chaves JWT (keys/)** | ğŸ”´ CrÃ­tico | âœ… SIM (secrets manager) |
| **VariÃ¡veis de ambiente** | ğŸ”´ CrÃ­tico | âœ… SIM (secrets manager) |
| **Logs** | ğŸŸ¢ Baixo | â³ Opcional (journald) |

---

## ğŸ“¦ PolÃ­tica de Backup

### RetenÃ§Ã£o

| Tipo de Backup | FrequÃªncia | RetenÃ§Ã£o | ResponsÃ¡vel |
|----------------|------------|----------|-------------|
| **Neon PITR** | ContÃ­nuo (WAL) | 7 dias | Neon (automÃ¡tico) |
| **pg_dump diÃ¡rio** | DiÃ¡rio (03:00 UTC) | 30 dias | GitHub Actions + S3 |
| **Snapshot semanal** | Semanal (domingos) | 90 dias | GitHub Actions + S3 |
| **Snapshot mensal** | Mensal (dia 1) | 1 ano | GitHub Actions + S3 |
| **CÃ³digo-fonte** | Cada push | Infinito | GitHub |

### RPO/RTO

| CenÃ¡rio | RPO (Perda MÃ¡xima) | RTO (Tempo de RecuperaÃ§Ã£o) |
|---------|-------------------|---------------------------|
| **Database corruption** | < 1 hora (Neon PITR) | < 2 horas |
| **Database deletion acidental** | < 24 horas (pg_dump) | < 4 horas |
| **Disaster total (AWS outage)** | < 24 horas | < 8 horas |
| **Application bug** | 0 (rollback cÃ³digo) | < 30 minutos |

**Meta:**
- **RPO:** < 24 horas
- **RTO:** < 4 horas

---

## ğŸš€ Backup AutomÃ¡tico (Neon)

### Neon Point-in-Time Recovery (PITR)

**O que Ã©:**
- Neon mantÃ©m backups contÃ­nuos via Write-Ahead Log (WAL)
- Permite restaurar para qualquer ponto no tempo dentro da janela de retenÃ§Ã£o

**ConfiguraÃ§Ã£o atual:**
```yaml
Plano: Pro
RetenÃ§Ã£o PITR: 7 dias
Snapshots automÃ¡ticos: Sim (1x/dia)
RegiÃ£o: us-east-2 (AWS)
```

**Como restaurar:**

1. **Via Neon Console:**
   - Acessar: https://console.neon.tech
   - Selecionar projeto: `barber-analytics-prod`
   - Clicar em "Branches" â†’ "Restore to point in time"
   - Escolher timestamp (ex: 2025-11-14 10:30:00 UTC)
   - Criar novo branch com dados restaurados

2. **Via CLI:**
```bash
# Instalar Neon CLI
npm install -g neonctl

# Autenticar
neonctl auth login

# Criar branch de restore
neonctl branches create \
  --project-id ep-winter-leaf-adhqz08p \
  --name "restore-2025-11-14" \
  --point-in-time "2025-11-14T10:30:00Z"

# Obter connection string do novo branch
neonctl connection-string restore-2025-11-14
```

**Vantagens:**
- âœ… AutomÃ¡tico (zero configuraÃ§Ã£o)
- âœ… Granularidade de segundos
- âœ… Sem impacto em performance
- âœ… Incluso no plano Pro

**LimitaÃ§Ãµes:**
- âš ï¸ RetenÃ§Ã£o limitada (7 dias no Pro, 30 dias no Business)
- âš ï¸ NÃ£o protege contra exclusÃ£o do projeto Neon

---

## ğŸ’¾ Backup Complementar (pg_dump)

### Por que pg_dump adicional?

- âœ… RetenÃ§Ã£o maior (30 dias vs 7 dias Neon)
- âœ… Backup off-site (S3, independente da Neon)
- âœ… Portabilidade (pode restaurar em qualquer PostgreSQL)
- âœ… ProteÃ§Ã£o contra exclusÃ£o acidental do projeto Neon

### ImplementaÃ§Ã£o via GitHub Actions

**Arquivo:** `.github/workflows/backup-database.yml`

```yaml
name: Database Backup

on:
  schedule:
    # DiÃ¡rio Ã s 03:00 UTC (00:00 BRT)
    - cron: '0 3 * * *'
  workflow_dispatch: # Permitir trigger manual

jobs:
  backup:
    name: Backup PostgreSQL
    runs-on: ubuntu-latest

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Install PostgreSQL client
        run: |
          sudo apt-get update
          sudo apt-get install -y postgresql-client

      - name: Create backup directory
        run: mkdir -p backups

      - name: Run pg_dump
        env:
          DATABASE_URL: ${{ secrets.DATABASE_URL_PROD }}
        run: |
          TIMESTAMP=$(date +%Y%m%d-%H%M%S)
          BACKUP_FILE="backups/barber-analytics-${TIMESTAMP}.sql"

          echo "Creating backup: $BACKUP_FILE"
          pg_dump "$DATABASE_URL" \
            --clean \
            --if-exists \
            --no-owner \
            --no-acl \
            --format=plain \
            --file="$BACKUP_FILE"

          # Comprimir backup
          gzip "$BACKUP_FILE"
          echo "BACKUP_FILE=${BACKUP_FILE}.gz" >> $GITHUB_ENV

      - name: Upload to S3
        env:
          AWS_ACCESS_KEY_ID: ${{ secrets.AWS_ACCESS_KEY_ID }}
          AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          AWS_REGION: us-east-1
          S3_BUCKET: barber-analytics-backups
        run: |
          # Instalar AWS CLI
          pip install awscli

          # Upload com metadata
          aws s3 cp "$BACKUP_FILE" \
            "s3://$S3_BUCKET/daily/$BACKUP_FILE" \
            --metadata "timestamp=$(date -Iseconds)" \
            --storage-class STANDARD_IA

          echo "âœ… Backup uploaded to S3"

      - name: Cleanup old backups (30 dias)
        env:
          AWS_ACCESS_KEY_ID: ${{ secrets.AWS_ACCESS_KEY_ID }}
          AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          AWS_REGION: us-east-1
          S3_BUCKET: barber-analytics-backups
        run: |
          # Deletar arquivos mais antigos que 30 dias
          aws s3 ls "s3://$S3_BUCKET/daily/" | \
            awk '{print $4}' | \
            while read file; do
              file_date=$(echo $file | grep -oP '\d{8}')
              days_old=$(( ($(date +%s) - $(date -d $file_date +%s)) / 86400 ))

              if [ $days_old -gt 30 ]; then
                echo "Deleting old backup: $file (${days_old} days old)"
                aws s3 rm "s3://$S3_BUCKET/daily/$file"
              fi
            done

      - name: Notify on failure
        if: failure()
        uses: 8398a7/action-slack@v3
        with:
          status: ${{ job.status }}
          text: 'âŒ Database backup FAILED!'
          webhook_url: ${{ secrets.SLACK_WEBHOOK_URL }}
```

### Secrets NecessÃ¡rios

Configurar no GitHub (Settings â†’ Secrets):

```bash
# Neon connection string
DATABASE_URL_PROD=postgresql://user:pass@ep-xxx.neon.tech/neondb?sslmode=require

# AWS S3 credentials
AWS_ACCESS_KEY_ID=AKIA...
AWS_SECRET_ACCESS_KEY=...

# Slack notifications (opcional)
SLACK_WEBHOOK_URL=https://hooks.slack.com/...
```

### Criar S3 Bucket

```bash
# Criar bucket
aws s3 mb s3://barber-analytics-backups \
  --region us-east-1

# Habilitar versionamento
aws s3api put-bucket-versioning \
  --bucket barber-analytics-backups \
  --versioning-configuration Status=Enabled

# Configurar lifecycle (deletar apÃ³s 30 dias)
cat > lifecycle.json << 'EOF'
{
  "Rules": [
    {
      "Id": "DeleteOldBackups",
      "Status": "Enabled",
      "Prefix": "daily/",
      "Expiration": {
        "Days": 30
      }
    }
  ]
}
EOF

aws s3api put-bucket-lifecycle-configuration \
  --bucket barber-analytics-backups \
  --lifecycle-configuration file://lifecycle.json
```

---

## ğŸ§ª Testes de Restore

### Objetivo

Validar que backups podem ser restaurados corretamente e o sistema funciona.

### Procedimento de Teste (Mensal)

**1. Escolher backup para teste:**
```bash
# Listar backups disponÃ­veis
aws s3 ls s3://barber-analytics-backups/daily/

# Escolher backup recente (ex: de ontem)
BACKUP_FILE=barber-analytics-20251114-030000.sql.gz
```

**2. Criar banco de teste (staging):**
```bash
# Via Neon CLI: Criar branch de teste
neonctl branches create \
  --project-id ep-winter-leaf-adhqz08p \
  --name "restore-test-$(date +%Y%m%d)" \
  --parent main

# Obter connection string
TEST_DB_URL=$(neonctl connection-string restore-test-20251115)
```

**3. Restaurar backup:**
```bash
# Baixar backup do S3
aws s3 cp "s3://barber-analytics-backups/daily/$BACKUP_FILE" .

# Descomprimir
gunzip $BACKUP_FILE

# Restaurar no banco de teste
psql "$TEST_DB_URL" < ${BACKUP_FILE%.gz}
```

**4. Validar dados:**
```bash
# Verificar contagem de registros
psql "$TEST_DB_URL" -c "
SELECT
  (SELECT COUNT(*) FROM tenants) as tenants,
  (SELECT COUNT(*) FROM users) as users,
  (SELECT COUNT(*) FROM receitas) as receitas,
  (SELECT COUNT(*) FROM despesas) as despesas,
  (SELECT COUNT(*) FROM assinaturas) as assinaturas;
"

# Resultado esperado:
#  tenants | users | receitas | despesas | assinaturas
# ---------+-------+----------+----------+-------------
#       15 |    42 |     1250 |      890 |          38
```

**5. Testar aplicaÃ§Ã£o:**
```bash
# Atualizar .env com connection string de teste
export DATABASE_URL="$TEST_DB_URL"

# Iniciar backend
cd backend
go run cmd/api/main.go

# Testar endpoint
curl http://localhost:8080/health
# Deve retornar: {"status":"healthy","database":"connected"}

# Testar login
curl -X POST http://localhost:8080/api/v1/auth/login \
  -H "Content-Type: application/json" \
  -d '{"email":"qa@barberpro.dev","password":"qa123456"}'
# Deve retornar access_token
```

**6. Medir tempo de restauraÃ§Ã£o:**
```bash
# Anotar duraÃ§Ã£o total do processo:
# - Download: X minutos
# - DescompressÃ£o: Y minutos
# - Restore: Z minutos
# Total: < 2 horas (meta RTO)
```

**7. Limpar ambiente de teste:**
```bash
# Deletar branch de teste apÃ³s validaÃ§Ã£o
neonctl branches delete restore-test-20251115
```

### Registro de Testes

Manter log em `docs/backup-tests.log`:

```
2025-11-15 10:00:00 UTC | Teste de Restore Mensal
Backup: barber-analytics-20251114-030000.sql.gz (450 MB)
Download: 3 min
Restore: 8 min
ValidaÃ§Ã£o: OK (15 tenants, 42 users, 1250 receitas)
RTO Real: 15 minutos âœ…
Status: SUCESSO âœ…
```

---

## ğŸš¨ Disaster Recovery Playbook

### CenÃ¡rios de Desastre

#### CenÃ¡rio 1: CorrupÃ§Ã£o de Dados (Acidental)

**Sintomas:**
- Dados inconsistentes (ex: receitas zeradas, usuÃ¡rios sumindo)
- Erros de integridade referencial
- AplicaÃ§Ã£o funciona mas dados corrompidos

**AÃ§Ãµes:**

1. **Identificar timestamp da corrupÃ§Ã£o:**
   ```bash
   # Revisar audit_logs
   psql "$DATABASE_URL" -c "
   SELECT * FROM audit_logs
   WHERE criado_em > NOW() - INTERVAL '24 hours'
   ORDER BY criado_em DESC;
   "
   ```

2. **Criar backup da situaÃ§Ã£o atual (por seguranÃ§a):**
   ```bash
   pg_dump "$DATABASE_URL" > corruption-backup-$(date +%Y%m%d).sql
   ```

3. **Restaurar via Neon PITR:**
   ```bash
   # Criar branch com dados de antes da corrupÃ§Ã£o
   neonctl branches create \
     --name "restore-before-corruption" \
     --point-in-time "2025-11-14T10:30:00Z"

   # Obter nova connection string
   NEW_DB_URL=$(neonctl connection-string restore-before-corruption)
   ```

4. **Validar dados restaurados:**
   ```bash
   # Testar queries crÃ­ticas
   psql "$NEW_DB_URL" -c "SELECT COUNT(*) FROM receitas;"
   ```

5. **Promover para produÃ§Ã£o:**
   ```bash
   # Atualizar DATABASE_URL nos secrets
   # Reiniciar backend com nova connection string
   ssh deploy@vps "sudo systemctl restart barber-api"
   ```

6. **Verificar aplicaÃ§Ã£o:**
   ```bash
   curl https://api.barberpro.dev/health
   ```

**RTO esperado:** < 2 horas

---

#### CenÃ¡rio 2: ExclusÃ£o Acidental de Tabela

**Sintomas:**
- Erro: `relation "users" does not exist`
- Backend crashando ao iniciar

**AÃ§Ãµes:**

1. **Parar trÃ¡fego para aplicaÃ§Ã£o:**
   ```bash
   # Retornar pÃ¡gina de manutenÃ§Ã£o no NGINX
   ssh deploy@vps "sudo systemctl stop barber-api"
   ```

2. **Baixar Ãºltimo backup pg_dump:**
   ```bash
   LATEST_BACKUP=$(aws s3 ls s3://barber-analytics-backups/daily/ | tail -1 | awk '{print $4}')
   aws s3 cp "s3://barber-analytics-backups/daily/$LATEST_BACKUP" .
   gunzip $LATEST_BACKUP
   ```

3. **Restaurar apenas tabela deletada:**
   ```bash
   # Extrair apenas CREATE + INSERT da tabela users
   grep -A 10000 "CREATE TABLE users" ${LATEST_BACKUP%.gz} > users_restore.sql

   # Aplicar no banco
   psql "$DATABASE_URL" < users_restore.sql
   ```

4. **Recriar Ã­ndices se necessÃ¡rio:**
   ```bash
   psql "$DATABASE_URL" -c "
   CREATE INDEX IF NOT EXISTS idx_users_tenant_id_email ON users(tenant_id, email);
   "
   ```

5. **Reiniciar aplicaÃ§Ã£o:**
   ```bash
   ssh deploy@vps "sudo systemctl start barber-api"
   ```

**RTO esperado:** < 1 hora

---

#### CenÃ¡rio 3: Disaster Total (AWS Region Down)

**Sintomas:**
- Neon inacessÃ­vel
- Toda regiÃ£o us-east-2 fora do ar
- AplicaÃ§Ã£o completamente offline

**AÃ§Ãµes:**

1. **Ativar comunicaÃ§Ã£o de emergÃªncia:**
   - Post em status page: "Sistema temporariamente indisponÃ­vel"
   - Notificar clientes via email/WhatsApp

2. **Provisionar novo banco em regiÃ£o diferente:**
   ```bash
   # Criar projeto Neon em us-west-2
   neonctl projects create \
     --name "barber-analytics-dr" \
     --region us-west-2
   ```

3. **Restaurar Ãºltimo backup:**
   ```bash
   # Baixar backup mais recente
   LATEST_BACKUP=$(aws s3 ls s3://barber-analytics-backups/daily/ | tail -1 | awk '{print $4}')
   aws s3 cp "s3://barber-analytics-backups/daily/$LATEST_BACKUP" .
   gunzip $LATEST_BACKUP

   # Restaurar em novo banco
   DR_DB_URL="postgresql://user:pass@ep-xxx-us-west-2.neon.tech/neondb"
   psql "$DR_DB_URL" < ${LATEST_BACKUP%.gz}
   ```

4. **Atualizar DNS:**
   ```bash
   # Apontar api.barberpro.dev para novo VPS/regiÃ£o
   # (Assumindo VPS multi-regiÃ£o ou novo deploy)
   ```

5. **Atualizar variÃ¡veis de ambiente:**
   ```bash
   # GitHub Secrets: DATABASE_URL â†’ novo connection string
   # VPS: /opt/barber-api/.env â†’ DATABASE_URL=$DR_DB_URL
   ```

6. **Deploy em nova regiÃ£o:**
   ```bash
   # Trigger GitHub Actions deploy
   # ou SSH manual
   ssh deploy@vps-dr "sudo systemctl restart barber-api"
   ```

7. **Verificar funcionamento:**
   ```bash
   curl https://api.barberpro.dev/health
   ```

**RTO esperado:** < 8 horas (cenÃ¡rio raro)

---

### Contatos de EmergÃªncia

| Papel | Nome | Contato | Responsabilidade |
|-------|------|---------|------------------|
| **Tech Lead** | Andrey Viana | andrey@barberpro.dev | DecisÃ£o final em DR |
| **DevOps Lead** | [TBD] | devops@barberpro.dev | ExecuÃ§Ã£o tÃ©cnica |
| **Neon Support** | support@neon.tech | Ticket + Slack | Suporte Neon |
| **AWS Support** | - | Console AWS | Suporte S3/EC2 |

### Checklist de AtivaÃ§Ã£o DR

- [ ] Identificar cenÃ¡rio de desastre
- [ ] Notificar stakeholders (Tech Lead, clientes)
- [ ] Acionar playbook correspondente
- [ ] Documentar cada aÃ§Ã£o em tempo real
- [ ] Validar restauraÃ§Ã£o com testes
- [ ] Comunicar resoluÃ§Ã£o aos clientes
- [ ] Realizar postmortem (48h apÃ³s incidente)

---

## ğŸ“Š Objetivos RTO/RPO

### DefiniÃ§Ãµes

- **RPO (Recovery Point Objective):** Perda mÃ¡xima de dados aceitÃ¡vel
- **RTO (Recovery Time Objective):** Tempo mÃ¡ximo de indisponibilidade

### Metas Atuais

| ServiÃ§o | RPO | RTO | ImplementaÃ§Ã£o |
|---------|-----|-----|---------------|
| **Database** | < 1 hora | < 2 horas | Neon PITR (7 dias) |
| **Database (disaster)** | < 24 horas | < 4 horas | pg_dump + S3 (30 dias) |
| **Backend (cÃ³digo)** | 0 (Git) | < 30 min | Git + CI/CD |
| **Frontend (cÃ³digo)** | 0 (Git) | < 30 min | Git + Vercel |
| **Chaves JWT** | N/A | < 1 hora | Secrets manager + backup manual |

### MediÃ§Ã£o de Sucesso

**CritÃ©rios:**
- âœ… Testes de restore mensais passando
- âœ… RTO real < meta definida
- âœ… RPO real < meta definida
- âœ… Zero perda de dados crÃ­ticos em 12 meses

**MÃ©tricas:**
- Ãšltima restauraÃ§Ã£o testada: [Data]
- Tempo de restore mÃ©dio: [X minutos]
- Taxa de sucesso de backups: [99.x%]

---

## âœ… Checklist de ValidaÃ§Ã£o

### Setup Inicial
- [ ] Neon PITR habilitado (7 dias retenÃ§Ã£o)
- [ ] GitHub Actions workflow criado (backup-database.yml)
- [ ] S3 bucket criado (barber-analytics-backups)
- [ ] Lifecycle policy configurada (30 dias)
- [ ] Secrets configurados (DATABASE_URL, AWS keys)

### Operacional
- [ ] Backups diÃ¡rios rodando com sucesso
- [ ] Alertas configurados (falha de backup â†’ Slack)
- [ ] Teste de restore realizado (mensal)
- [ ] DocumentaÃ§Ã£o atualizada (este documento)
- [ ] Equipe treinada em procedimentos DR

### ValidaÃ§Ã£o Trimestral
- [ ] ExercÃ­cio de DR completo (simular disaster)
- [ ] Review de RTO/RPO (ajustar metas se necessÃ¡rio)
- [ ] Atualizar contatos de emergÃªncia
- [ ] Audit de backups (verificar integridade de 10 arquivos aleatÃ³rios)

---

## ğŸ“š ReferÃªncias

- [Neon Backup Documentation](https://neon.tech/docs/introduction/point-in-time-restore)
- [PostgreSQL Backup Best Practices](https://www.postgresql.org/docs/current/backup.html)
- [AWS S3 Lifecycle Policies](https://docs.aws.amazon.com/AmazonS3/latest/userguide/object-lifecycle-mgmt.html)
- [Disaster Recovery Planning (AWS)](https://aws.amazon.com/disaster-recovery/)

---

**Ãšltima AtualizaÃ§Ã£o:** 15/11/2025
**VersÃ£o:** 1.0.0
**ResponsÃ¡vel:** Equipe DevOps
**RevisÃ£o:** Trimestral
